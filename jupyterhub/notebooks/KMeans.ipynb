{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $k$-Means Algorithm\n",
    "====================\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The k-means algorithm is used to partition a given set of observations into a predefined amount of $k$ clusters. The algorithm as described by MacQueen in 1967, starts with a random set of $k$ center-points ($\\mu$). During each update step, all observations $x$ are assigned to their nearest center-point. In the standard algorithm, only one assignment to one center is possible. If multiple centers have the same distance to the observation, a random one would be chosen.\n",
    "\n",
    "$S_i^{(t)} = \\big \\{ x_p : \\big \\| x_p - \\mu^{(t)}_i \\big \\|^2 \\le \\big \\| x_p - \\mu^{(t)}_j \\big \\|^2 \\ \\forall j, 1 \\le j \\le k \\big\\}$\n",
    "\n",
    "\n",
    "Afterwards, the center-points are repositioned by calculating the mean of the assigned observations to the respective center-points.\n",
    "\n",
    "\n",
    "$\\mu^{(t+1)}_i = \\frac{1}{|S^{(t)}_i|} \\sum_{x_j \\in S^{(t)}_i} x_j$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by generating some artificial data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.jet() # set the color map. When your colors are lost, re-run this.\n",
    "import sklearn.datasets as datasets\n",
    "X, Y = datasets.make_blobs(centers=4, cluster_std=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, we first *plot* the data to get a feeling of what we're dealing with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0], X[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data looks like it may contain four different \"types\" of data point. \n",
    "\n",
    "In fact, this is how it was created above.\n",
    "\n",
    "We can plot this information as well, using color:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0], X[:,1], c=Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally, you do not know the information in `Y`, however.\n",
    "\n",
    "You could try to recover it from the data alone.\n",
    "\n",
    "This is what the kMeans algorithm does. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(4, random_state=8)\n",
    "Y_hat = kmeans.fit(X).labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the label assignments should be quite similar to `Y`, up to a different ordering of the colors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0], X[:,1], c=Y_hat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, you're not so much interested in the assignments to the means. \n",
    "\n",
    "You'll want to have a closer look at the means $\\mu$.\n",
    "\n",
    "The means in $\\mu$ can be seen as *representatives* of their respective cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0], X[:,1], c=Y_hat, alpha=0.4)\n",
    "mu = kmeans.cluster_centers_\n",
    "plt.scatter(mu[:,0], mu[:,1], s=100, c=np.unique(Y_hat))\n",
    "print(mu)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $k$-Means on Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this final example, we use the $k$-Means algorithm on the classical MNIST dataset.\n",
    "\n",
    "The MNIST dataset contains images of hand-written digits. \n",
    "\n",
    "Let's first fetch the dataset from the internet (which may take a while, note the asterisk [*]):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits.images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.utils import shuffle\n",
    "X_digits, Y_digits = (digits.data, digits.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at some of the instances in the dataset we just loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\"image\", cmap=\"binary\") # use black/white palette for plotting\n",
    "for i in range(10):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(X_digits[i].reshape(8,8))\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: This takes quite a few seconds, so be patient until the asterisk [*] disappears!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(10)\n",
    "mu_digits = kmeans.fit(X_digits).cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a closer look at the means. Even though there are 10 digits, some of them are over/under-represented. Do you understand why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "for i in range(2*(mu_digits.shape[0]//2)): # loop over all means\n",
    "    plt.subplot(2,mu_digits.shape[0]//2,i+1)\n",
    "    plt.imshow(mu_digits[i].reshape(8,8))\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing with $k$-Means - Advanced visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now going to apply PCA to the dataset and try to get a feel for the distribution of each of the handwritten digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now fit another KMeans classifier on 2D PCA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reduced_data = PCA(n_components=2).fit_transform(X_digits)\n",
    "kmeans = KMeans(init='k-means++', n_clusters=10, n_init=10)\n",
    "kmeans.fit(reduced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "h = .02     # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "\n",
    "x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\n",
    "y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Obtain labels for each point in mesh. Use last trained model.\n",
    "Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1, figsize=(12,12))\n",
    "plt.clf()\n",
    "plt.imshow(Z, interpolation='nearest',\n",
    "           extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "           cmap=plt.cm.Paired,\n",
    "           aspect='auto', origin='lower')\n",
    "\n",
    "plt.plot(reduced_data[:, 0], reduced_data[:, 1], 'k.', markersize=2)\n",
    "# Plot the centroids as a white X\n",
    "centroids = kmeans.cluster_centers_\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1],\n",
    "            marker='x', s=169, linewidths=3,\n",
    "            color='w', zorder=10)\n",
    "plt.title('K-means clustering on the digits dataset (PCA-reduced data)\\n'\n",
    "          'Centroids are marked with white cross')\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Playing with this Notebook\n",
    "==========================\n",
    "\n",
    "Try to see what happens when you\n",
    "\n",
    "- Increase the standard deviation of the clusters in this notebook\n",
    "- Choose a \"wrong\" number of clusters by:\n",
    "  1. changing the number of clusters generated\n",
    "  2. changing the number of clusters used by KMeans\n",
    "\n",
    "- What happens to result of the $k$-Means algorithm when you have multiplied one axis of the matrix $X$ with a large value?\n",
    "\n",
    "  For example, the 0-th axis with 100:\n",
    "\n",
    "  `X[:,0] *= 100`\n",
    "\n",
    "  Why does the result change?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
